import numpy as np
import math
import matplotlib.pyplot as plt
import random
from sklearn.datasets import make_blobs
from mpl_toolkits.mplot3d import Axes3D

# '''
# 定义目标判别函数
# '''
# def aim_discriminant(x):
#     return 3 * x + 2

'''
sigmoid函数a=1/(1+exp(-b)
'''
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

'''
自己生成数据
根据是否满足贝叶斯假设，在范围[0,1]上生成sample_number个二维点集，并将其均匀分为两类
并添加一个N(0,1)的高斯噪声
'''
def create_datas(sample_number, satisfy_naive):
    half = np.ceil(sample_number / 2).astype(np.int32)  #sample_number的一半
    variance = 0.2  #随机变量方差
    covariance_xy = 0.01  #两个维度的协方差
    point_mean1 = [-0.7, -0.3]  #类别1的均值
    point_mean2 = [0.7, 0.3]  #类别2的均值
    train_point_X = np.zeros((sample_number, 2))  #二维的点集
    classification_Y = np.zeros(sample_number)  #点集的分类
    if satisfy_naive:  #满足朴素贝叶斯假设
        train_point_X[:half, :] = np.random.multivariate_normal(point_mean1, [[variance, 0], [0, variance]], size=half)  #生成half个类别1的1*2数组，每个数组含有两个维度
        train_point_X[half:, :] = np.random.multivariate_normal(point_mean2, [[variance, 0], [0, variance]], size=sample_number - half)  #生成half个类别2的1*2数组，每个数组含有两个维度
        classification_Y[:half] = 0  #将前half个数组标记为类别1
        classification_Y[half:] = 1  #将后half个数组标记为类别2
    else:  #不满足朴素贝叶斯假设
        train_point_X[:half, :] = np.random.multivariate_normal(point_mean1, [[variance, covariance_xy], [covariance_xy, variance]], size=half) #生成half个类别1的1*2数组，每个数组含有两个维度
        train_point_X[half:, :] = np.random.multivariate_normal(point_mean2, [[variance, covariance_xy], [covariance_xy, variance]], size=sample_number - half) #生成half个类别2的1*2数组，每个数组含有两个维度
        classification_Y[:half] = 0  #将前half个数组标记为类别1
        classification_Y[half:] = 1  #将后half个数组标记为类别2
    return train_point_X, classification_Y  #返回生成的所有点及类别

'''
对于train_point_X中，含有二维数据，分别对应横坐标x和纵坐标y
对于classification_Y,为train_point_X中两种数据的点对应的类别
根据train_point_X和classification_Y画出二维坐标下的点图，然后画出分界判别函数boundary_check_function
'''
def draw_picture(train_point_X, classification_Y, boundary_check_function):
    if boundary_check_function:  #绘制分界判定函数boundary_check_function
        d_length=max(train_point_X[:, 0]) - min(train_point_X[:, 0])  #找到横坐标x的极差
        real_x = np.linspace(min(train_point_X[:, 0]) , min(train_point_X[:, 0]) + d_length , 50)  #在x的范围内均匀产生50个点
        real_y = boundary_check_function(real_x)   #对real_x每个点调用boundary_check_function求解对应的real_y
        plt.plot(real_x, real_y, 'r', label='boundary_check_function')   #绘制图像
    plot = plt.scatter(train_point_X[:, 0], train_point_X[:, 1], s=30 , c=classification_Y, marker='o',cmap=plt.cm.Spectral) #绘制两种点集
    plt.xlabel('x')
    plt.ylabel('y')
    plt.legend(loc=1)
    plt.title('The regression curve')
    plt.show()

'''
根据迭代次数cycle_times_list和对应的误差loss_list画出损失函数图像
参数中，cycle_times_list为迭代次数表，loss_list为对应的误差表
'''
def draw_picture_loss(cycle_times_list, loss_list):
    plt.plot(cycle_times_list, loss_list, 'r', label='loss_function')
    plt.xlabel('cycle_times')
    plt.ylabel('loss')
    plt.legend(loc=1)
    plt.title('the loss_funciton')
    plt.show()

'''
根据公式得到点集的极大条件似然得到极大条件似然l(W)
'''
def maximum_conditional_likelihood(train_point_X, classification_Y, w):
    total_points = np.size(train_point_X, axis=0)  #得到train_point_X的行数，即点集个数
    predict = np.zeros((total_points, 1))
    for i in range(total_points):
        predict[i] = w.dot(train_point_X[i].T)  #极大条件似然中的exp中的部分，即求和wi * Xl
    t = 0
    for i in range(total_points):
        t += np.log(1 + np.exp(predict[i]))  #极大条件似然中ln的部分，即ln ( 1 + exp ( 求和wi * Xi ) )
    MCLE=classification_Y.dot(predict) - t   #得到极大条件似然l(w)
    return MCLE

'''
加惩罚项的梯度下降法
对于train_point_X和classification_Y对参数w做梯度下降，对损失函数使用梯度下降法，当误差函数收敛到期望的最小值时，得到此时的w并返回w
参数中：
迭代最大次数为cycle_times
下降步长descending_step_size
迭代误差iteration_error
数据点集维度dimension
惩罚项参数lamda
'''
def descent_gradient_add_errorfunction(train_point_X, classification_Y, cycle_times, descending_step_size, iteration_error, dimension, lamda):
    total_points = np.size(train_point_X, axis=0)  #得到train_point_X的行数，即点集个数
    w = np.ones((1, dimension + 1))   #生成系数矩阵w，一个列数为dimension + 1，行数为1的矩阵，元素值全为1
    cycle_times_list = np.zeros(cycle_times)  #迭代次数统计
    loss_list = np.zeros(cycle_times)  #迭代次数对应的损失函数值统计
    for i in range(cycle_times):
        old_loss = - 1 / total_points * maximum_conditional_likelihood(train_point_X, classification_Y, w)  #原先损失函数的值
        t = np.zeros((total_points, 1))
        for j in range(total_points):
            t[j] = w.dot(train_point_X[j].T)   #极大条件似然中的exp中的部分，即求和wi * Xl
        gradient = - 1 / total_points * (classification_Y - sigmoid(t.T)).dot(train_point_X)
        w = w - descending_step_size * lamda * w - descending_step_size * gradient  #梯度下降加惩罚项的迭代公式
        new_loss = - 1 / total_points * maximum_conditional_likelihood(train_point_X, classification_Y, w)  #新的损失函数的值
        cycle_times_list[i] = i  #储存迭代次数
        loss_list[i] = new_loss  #储存每次迭代对应的损失函数值
        # if i % 100 == 0:
        #     print('迭代次数=', i, ', 对应的损失函数值=', new_loss, ', 对应的系数w=', w, '对应的梯度=', gradient)
        if abs(new_loss - old_loss) < iteration_error:  #如果新的误差函数值与旧的误差函数值的差小于迭代误差则终止迭代
            cycle_times_list = cycle_times_list[:i + 1]
            loss_list = loss_list[:i + 1]
            print('迭代次数=', i, ', 对应的损失函数值=', new_loss, ', 对应的系数w=', w, '对应的梯度=', gradient)
            break
        if new_loss > old_loss:  #当新的误差函数值大于旧的误差函数值时，将步长变为原来的一半
            descending_step_size *= 0.5
    return w, cycle_times_list, loss_list

'''
自定义二维点集进行试验并绘制图像
参数中：sample_number为点集中点的个数，lamda为惩罚项系数（可以为0，此时没有惩罚项），satisfy_naive为是否满足朴素贝叶斯假设
cycle_times为梯度下降迭代最大次数,descending_step_size为梯度下降下降步长,iteration_error为梯度下降迭代误差
'''
def design_experiment(sample_number, lamda, satisfy_naive , cycle_times , descending_step_size , iteration_error):
    train_point_X, classification_Y = create_datas(sample_number, satisfy_naive)  # 生成sample_number个二维点集数据
    train_all = np.ones((sample_number, 3))  #创建行为sample_number，列为3的矩阵train_all
    train_all[:, 1] = train_point_X[:, 0]  #将生成点集的第一个维度放入train_all的第二列
    train_all[:, 2] = train_point_X[:, 1]  #将生成点集的第二个维度放入train_all的第三列
    dimension = np.size(train_point_X, axis=1)
    w, cycle_times_list, loss_list = descent_gradient_add_errorfunction(train_all, classification_Y, cycle_times, descending_step_size, iteration_error, dimension, lamda)
    w = w.reshape(-1)   #得到的w是一个一行三列的矩阵,需要先将w改成行向量
    function_coefficient = -(w / w[2])[0:2]  #w整体除y的系数然后移项得到决策面系数
    boundary_check_function = np.poly1d(function_coefficient[::-1])  #将function_coefficient从后往前倒序然后调用poly1d得到多项式函数
    print('分界判别函数为: y = ', boundary_check_function)
    draw_picture(train_point_X, classification_Y, boundary_check_function)
    draw_picture_loss(cycle_times_list, loss_list)


cycle_times = 1000000
descending_step_size = 0.1
iteration_error = 1e-5
# design_experiment(200,0,True,cycle_times,descending_step_size,iteration_error)
#
# design_experiment(200,0,False,cycle_times,descending_step_size,iteration_error)
#
# design_experiment(200,0.001,True,cycle_times,descending_step_size,iteration_error)
#
# design_experiment(200,0.001,False,cycle_times,descending_step_size,iteration_error)
#
'''
Skin_NonSkin数据集是三个维度的，所以可以画出三维的图像。
'''
def Skin_NonSkin_draw_picture(train_point_X, classification_Y, function_coefficient):
    fig = plt.figure()
    ax = Axes3D(fig)
    ax.set_title('3D of the regression curve')
    ax.scatter(train_point_X[:,0], train_point_X[:,1], train_point_X[:,2], c=classification_Y,cmap=plt.cm.Spectral)
    real_x = np.arange(np.min(train_point_X[:,0]), np.max(train_point_X[:,0]), 1)
    real_y = np.arange(np.min(train_point_X[:,1]), np.max(train_point_X[:,1]), 1)
    real_X, real_Y = np.meshgrid(real_x, real_y)
    real_z = function_coefficient[0] + function_coefficient[1] * real_X + function_coefficient[2] * real_Y
    ax.plot_surface(real_x, real_y, real_z, rstride=1, cstride=1)
    ax.set_zlim(np.min(real_z) - 10, np.max(real_z) + 10)
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    ax.set_zlabel('z')
    plt.show()

'''
读入Skin_NonSkin.csv文件，对数据进行拆分，拆分成训练集合测试集
由于原文件中数据量巨大，所以对数据集以50步长取部分数据作为数据集
'''
def Skin_NonSkin_getdata():
    # all_data = np.loadtxt('./Skin_NonSkin.txt', dtype=np.int32)
    all_data = np.loadtxt(open('./Skin_NonSkin.csv'),delimiter=",",skiprows=0)  #读取文件中的所有数据
    np.random.shuffle(all_data)  #将原数据集打乱，分成训练集和测试集
    test_rate = 0.2  #测试集所占比例
    all_data_size = np.size(all_data, axis=0)  #总数据集数据数量
    train_data_X = all_data[:int(test_rate * all_data_size), :]  #训练集数据
    test_data_x = all_data[int(test_rate * all_data_size):, :]  #测试集数据
    dimension = np.size(all_data, axis=1) - 1  #训练集样本维度
    step = 50  # 由于Skin_NonSkin的数据集太大，所以采用步长为50的方式取数据
    train_point_X = train_data_X[:, 0:dimension]  #将所有数据集赋给train_point_X
    train_point_X = train_point_X[::step]   #以step为间隔取数据
    train_point_X = train_point_X - 100  #对样本点进行坐标平移，方便在3D图中显示
    train_classification_Y = train_data_X[:, dimension:dimension + 1] - 1  #因为数据集的分类是1/2,需要减1变成0/1
    train_classification_Y = train_classification_Y[::step]  #以step为间隔取数据
    train_size = np.size(train_point_X, axis=0)  #训练集数据总数
    train_classification_Y = train_classification_Y.reshape(train_size)  #将矩阵转化为行向量
    test_point_X = test_data_x[:, 0:dimension] #将所有数据集赋给test_point_X
    test_point_X = test_point_X[::step] - 100  #对样本点进行坐标平移，方便在3D图中显示
    test_classification_Y = test_data_x[:, dimension:dimension + 1] - 1  #因为数据集的分类是1/2,需要减1变成0/1
    test_classification_Y = test_classification_Y[::step]  #以step为间隔取数据
    test_size = np.size(test_point_X, axis=0)  #测试集数据总数
    test_classification_Y = test_classification_Y.reshape(test_size)  #将矩阵转化为行向量
    return train_point_X, train_classification_Y, test_point_X, test_classification_Y

'''
使用Skin_NonSkin.csv上的数据进行试验
参数中lamda为惩罚项系数，cycle_times为梯度下降迭代最大次数,descending_step_size为梯度下降下降步长,iteration_error为梯度下降迭代误差
'''
def Skin_NonSkin_experiment(lamda ,cycle_times , descending_step_size , iteration_error):
    train_point_X, train_classification_Y, test_point_X, test_classification_Y = Skin_NonSkin_getdata()  #得到Skin_NonSkin.csv上的训练集样本和测试集样本
    train_size = np.size(train_point_X, axis=0)  #训练集样本数量
    test_size = np.size(test_point_X, axis=0)  #测试集样本数量
    dimension = np.size(train_point_X, axis=1)  #样本维度
    train_all = np.ones((train_size, dimension + 1)) #创建行为train_size，列为样本维度+1的矩阵train_all
    for i in range(dimension):  # 依次将训练集样本的每一个维度放入train_all的下一个维度
        train_all[:, i + 1] = train_point_X[:, i]
    w, cycle_times_list, loss_list = descent_gradient_add_errorfunction(train_all, train_classification_Y, cycle_times, descending_step_size, iteration_error, dimension , lamda)
    w = w.reshape(-1)  #得到的w是一个一行dimension + 1列的矩阵,需要先将w改成行向量
    function_coefficient = - (w / w[dimension ])[0:dimension ]  #w整体除y的系数然后移项得到决策面系数
    Skin_NonSkin_draw_picture(train_point_X, train_classification_Y, function_coefficient)
    draw_picture_loss(cycle_times_list, loss_list)
    #计算测试集的准确率
    label = np.ones(test_size)
    hit_count = 0
    test_all = np.ones((test_size, dimension  + 1)) #创建行为train_size，列为样本维度+1的矩阵test_all
    for i in range(dimension):  # 依次将测试集样本的每一个维度放入train_all的下一个维度
        test_all[:, i + 1] = test_point_X[:, i]
    for i in range(test_size):  #对每种预测给label进行赋值
        if w.dot(test_all[i].T) >= 0:
            label[i] = 1
        else:
            label[i] = 0
    for i in range(test_size):
        if label[i] == test_classification_Y[i]:  #如果预测的结果与真实结果相同计数加一
            hit_count += 1
    hit_rate = hit_count / test_size
    print('数据的测试集的准确率为：',hit_rate)

cycle_times1 = 1000000
descending_step_size1 = 0.001
iteration_error1 = 1e-5

# Skin_NonSkin_experiment(0,cycle_times1,descending_step_size1,iteration_error1)

# Skin_NonSkin_experiment(0.01,cycle_times1,descending_step_size1,iteration_error1)

'''
读入data_banknote_authentication.csv文件，对数据进行拆分，拆分成训练集合测试集
'''
def data_banknote_authentication_getdata():
    # all_data = np.loadtxt('./data_banknote_authentication.txt',dtype=np.float32)
    all_data = np.loadtxt(open('./data_banknote_authentication.csv'), delimiter=",", skiprows=0)  #读取文件中的所有数据
    np.random.shuffle(all_data)  #将原数据集打乱，分成训练集和测试集
    test_rate = 0.2  #测试集所占比例
    all_data_size = np.size(all_data, axis=0)  #总数据集数据数量
    train_data_X = all_data[:int(test_rate * all_data_size), :]  #训练集数据
    test_data_x = all_data[int(test_rate * all_data_size):, :]  #测试集数据
    dimension  = np.size(all_data, axis=1) - 1  #训练集样本维度
    #消除exp溢出，防止数据太大导致exp溢出
    for i in range(dimension):  #对于样本的所有维度
        d_length = max(train_data_X[:, i]) - min(train_data_X[:, i])   #计算最大值和最小值之间的极差
        for j in range(np.size(train_data_X , axis=0 )):   #对于每一维度的所有数
            train_data_X[j, i] = (max(train_data_X[:, i]) - train_data_X[j, i]) /  d_length  #将其化为[0,1]之间的值，防止exp溢出
    train_point_X = train_data_X[:, 0:dimension ] #将所有数据集赋给train_point_X
    train_classification_Y = train_data_X[:, dimension :dimension  + 1] #为train_classification_Y赋值为0/1
    train_size = np.size(train_point_X, axis=0) #训练集数据总数
    train_classification_Y = train_classification_Y .reshape(train_size)  #将矩阵转化为行向量
    test_point_X = test_data_x[:, 0:dimension ] #将所有数据集赋给test_point_X
    test_classification_Y = test_data_x[:, dimension :dimension  + 1] #为test_classification_Y赋值为0/1
    test_size = np.size(test_point_X, axis=0) #测试集数据总数
    test_classification_Y = test_classification_Y.reshape(test_size)  #将矩阵转化为行向量
    return train_point_X, train_classification_Y , test_point_X, test_classification_Y

'''
使用data_banknote_authentication.csv上的数据进行试验
参数中lamda为惩罚项系数，cycle_times为梯度下降迭代最大次数,descending_step_size为梯度下降下降步长,iteration_error为梯度下降迭代误差
'''
def data_banknote_authentication_exp(lamda ,cycle_times , descending_step_size , iteration_error):
    train_point_X, train_classification_Y , test_point_X, test_classification_Y = data_banknote_authentication_getdata()
    train_size = np.size(train_point_X, axis=0)  #训练集样本数量
    test_size = np.size(test_point_X, axis=0)  #测试集样本数量
    dimension = np.size(train_point_X, axis=1)  #样本维度
    # 构造训练集样本矩阵
    train_all = np.ones((train_size, dimension  + 1)) #创建行为train_size，列为样本维度+1的矩阵train_all
    for i in range(dimension):  #依次将训练集样本的每一个维度放入train_all的下一个维度
        train_all[:, i + 1] = train_point_X[:, i]
    w, cycle_times_list, loss_list = descent_gradient_add_errorfunction(train_all, train_classification_Y, cycle_times, descending_step_size, iteration_error, dimension , lamda)
    w = w.reshape(-1) #得到的w是一个一行dimension + 1列的矩阵,需要先将w改成行向量
    function_coefficient = - (w / w[dimension ])[0:dimension ]  #w整体除y的系数然后移项得到决策面系数
    draw_picture_loss(cycle_times_list, loss_list)
    #计算测试集准确率
    label = np.ones(test_size)
    hit_count = 0
    test_all = np.ones((test_size, dimension + 1)) #创建行为train_size，列为样本维度+1的矩阵test_all
    for i in range(dimension ):  #依次将测试集样本的每一个维度放入train_all的下一个维度
        test_all[:, i + 1] = test_point_X[:, i]
    for i in range(test_size): #对每种预测给label进行赋值
        if np.dot(w, test_all[i].T) >= 0:
            label[i] = 1
        else:
            label[i] = 0
    for i in range(test_size):
        if label[i] == test_classification_Y[i]: #如果预测的结果与真实结果相同计数加一
            hit_count += 1
    hit_rate = hit_count / test_size
    print('数据的测试集的准确率为：', hit_rate)

cycle_times2 = 1000000
descending_step_size2 = 0.1
iteration_error2 = 1e-5

# data_banknote_authentication_exp(0,cycle_times2,descending_step_size2,iteration_error2)
#
# data_banknote_authentication_exp(0.01,cycle_times2,descending_step_size2,iteration_error2)

'''
读入blood.csv文件，对数据进行拆分，拆分成训练集合测试集
'''
def blood_getdata():
    all_data = np.loadtxt(open('./blood.csv'), delimiter=",", skiprows=0)  #读取文件中的所有数据
    np.random.shuffle(all_data)  #将原数据集打乱，分成训练集和测试集
    test_rate = 0.2  #测试集所占比例
    all_data_size = np.size(all_data, axis=0)  #总数据集数据数量
    train_data_X = all_data[:int(test_rate * all_data_size), :]  #训练集数据
    test_data_x = all_data[int(test_rate * all_data_size):, :]  #测试集数据
    dimension  = np.size(all_data, axis=1) - 1  #训练集样本维度
    #消除exp溢出，防止数据太大导致exp溢出
    for i in range(dimension):  #对于样本的所有维度
        d_length = max(train_data_X[:, i]) - min(train_data_X[:, i])   #计算最大值和最小值之间的极差
        for j in range(np.size(train_data_X , axis=0 )):   #对于每一维度的所有数
            train_data_X[j, i] = (max(train_data_X[:, i]) - train_data_X[j, i]) /  d_length  #将其化为[0,1]之间的值，防止exp溢出
    train_point_X = train_data_X[:, 0:dimension ] #将所有数据集赋给train_point_X
    train_classification_Y = train_data_X[:, dimension :dimension  + 1] #为train_classification_Y赋值为0/1
    train_size = np.size(train_point_X, axis=0) #训练集数据总数
    train_classification_Y = train_classification_Y .reshape(train_size)  #将矩阵转化为行向量
    test_point_X = test_data_x[:, 0:dimension ] #将所有数据集赋给test_point_X
    test_classification_Y = test_data_x[:, dimension :dimension  + 1] #为test_classification_Y赋值为0/1
    test_size = np.size(test_point_X, axis=0) #测试集数据总数
    test_classification_Y = test_classification_Y.reshape(test_size)  #将矩阵转化为行向量
    return train_point_X, train_classification_Y , test_point_X, test_classification_Y

'''
使用blood.csv上的数据进行试验
参数中lamda为惩罚项系数，cycle_times为梯度下降迭代最大次数,descending_step_size为梯度下降下降步长,iteration_error为梯度下降迭代误差
'''
def blood_exp(lamda ,cycle_times , descending_step_size , iteration_error):
    train_point_X, train_classification_Y , test_point_X, test_classification_Y = blood_getdata()
    train_size = np.size(train_point_X, axis=0)  #训练集样本数量
    test_size = np.size(test_point_X, axis=0)  #测试集样本数量
    dimension = np.size(train_point_X, axis=1)  #样本维度
    # 构造训练集样本矩阵
    train_all = np.ones((train_size, dimension  + 1)) #创建行为train_size，列为样本维度+1的矩阵train_all
    for i in range(dimension):  #依次将训练集样本的每一个维度放入train_all的下一个维度
        train_all[:, i + 1] = train_point_X[:, i]
    w, cycle_times_list, loss_list = descent_gradient_add_errorfunction(train_all, train_classification_Y, cycle_times, descending_step_size, iteration_error, dimension , lamda)
    w = w.reshape(-1) #得到的w是一个一行dimension + 1列的矩阵,需要先将w改成行向量
    function_coefficient = - (w / w[dimension ])[0:dimension ]  #w整体除y的系数然后移项得到决策面系数
    draw_picture_loss(cycle_times_list, loss_list)
    #计算测试集准确率
    label = np.ones(test_size)
    hit_count = 0
    test_all = np.ones((test_size, dimension + 1)) #创建行为train_size，列为样本维度+1的矩阵test_all
    for i in range(dimension ):  #依次将测试集样本的每一个维度放入train_all的下一个维度
        test_all[:, i + 1] = test_point_X[:, i]
    for i in range(test_size): #对每种预测给label进行赋值
        if np.dot(w, test_all[i].T) >= 0:
            label[i] = 1
        else:
            label[i] = 0
    for i in range(test_size):
        if label[i] == test_classification_Y[i]: #如果预测的结果与真实结果相同计数加一
            hit_count += 1
    hit_rate = hit_count / test_size
    print('数据的测试集的准确率为：', hit_rate)

cycle_times3 = 1000000
descending_step_size3 = 0.1
iteration_error3 = 1e-5

# blood_exp(0,cycle_times3,descending_step_size3,iteration_error3)
#
# blood_exp(0.01,cycle_times3,descending_step_size3,iteration_error3)

'''
读入heart.csv文件，对数据进行拆分，拆分成训练集合测试集
'''
def heart_getdata():
    all_data = np.loadtxt(open('./heart.csv'), delimiter=",", skiprows=0)  #读取文件中的所有数据
    np.random.shuffle(all_data)  #将原数据集打乱，分成训练集和测试集
    test_rate = 0.2  #测试集所占比例
    all_data_size = np.size(all_data, axis=0)  #总数据集数据数量
    train_data_X = all_data[:int(test_rate * all_data_size), :]  #训练集数据
    test_data_x = all_data[int(test_rate * all_data_size):, :]  #测试集数据
    dimension  = np.size(all_data, axis=1) - 1  #训练集样本维度
    #消除exp溢出，防止数据太大导致exp溢出
    for i in range(dimension):  #对于样本的所有维度
        d_length = max(train_data_X[:, i]) - min(train_data_X[:, i])   #计算最大值和最小值之间的极差
        for j in range(np.size(train_data_X , axis=0 )):   #对于每一维度的所有数
            train_data_X[j, i] = (max(train_data_X[:, i]) - train_data_X[j, i]) /  d_length  #将其化为[0,1]之间的值，防止exp溢出
    train_point_X = train_data_X[:, 0:dimension ] #将所有数据集赋给train_point_X
    train_classification_Y = train_data_X[:, dimension :dimension  + 1] #为train_classification_Y赋值为0/1
    train_size = np.size(train_point_X, axis=0) #训练集数据总数
    train_classification_Y = train_classification_Y .reshape(train_size)  #将矩阵转化为行向量
    test_point_X = test_data_x[:, 0:dimension ] #将所有数据集赋给test_point_X
    test_classification_Y = test_data_x[:, dimension :dimension  + 1] #为test_classification_Y赋值为0/1
    test_size = np.size(test_point_X, axis=0) #测试集数据总数
    test_classification_Y = test_classification_Y.reshape(test_size)  #将矩阵转化为行向量
    return train_point_X, train_classification_Y , test_point_X, test_classification_Y

'''
使用heart.csv上的数据进行试验
参数中lamda为惩罚项系数，cycle_times为梯度下降迭代最大次数,descending_step_size为梯度下降下降步长,iteration_error为梯度下降迭代误差
'''
def heart_exp(lamda ,cycle_times , descending_step_size , iteration_error):
    train_point_X, train_classification_Y , test_point_X, test_classification_Y = heart_getdata()
    train_size = np.size(train_point_X, axis=0)  #训练集样本数量
    test_size = np.size(test_point_X, axis=0)  #测试集样本数量
    dimension = np.size(train_point_X, axis=1)  #样本维度
    # 构造训练集样本矩阵
    train_all = np.ones((train_size, dimension  + 1)) #创建行为train_size，列为样本维度+1的矩阵train_all
    for i in range(dimension):  #依次将训练集样本的每一个维度放入train_all的下一个维度
        train_all[:, i + 1] = train_point_X[:, i]
    w, cycle_times_list, loss_list = descent_gradient_add_errorfunction(train_all, train_classification_Y, cycle_times, descending_step_size, iteration_error, dimension , lamda)
    w = w.reshape(-1) #得到的w是一个一行dimension + 1列的矩阵,需要先将w改成行向量
    function_coefficient = - (w / w[dimension ])[0:dimension ]  #w整体除y的系数然后移项得到决策面系数
    draw_picture_loss(cycle_times_list, loss_list)
    #计算测试集准确率
    label = np.ones(test_size)
    hit_count = 0
    test_all = np.ones((test_size, dimension + 1)) #创建行为train_size，列为样本维度+1的矩阵test_all
    for i in range(dimension ):  #依次将测试集样本的每一个维度放入train_all的下一个维度
        test_all[:, i + 1] = test_point_X[:, i]
    for i in range(test_size): #对每种预测给label进行赋值
        if np.dot(w, test_all[i].T) >= 0:
            label[i] = 1
        else:
            label[i] = 0
    for i in range(test_size):
        if label[i] == test_classification_Y[i]: #如果预测的结果与真实结果相同计数加一
            hit_count += 1
    hit_rate = hit_count / test_size
    print('数据的测试集的准确率为：', hit_rate)

cycle_times4 = 1000000
descending_step_size4 = 0.1
iteration_error4 = 1e-5

# heart_exp(0,cycle_times4,descending_step_size4,iteration_error4)
#
# heart_exp(0.01,cycle_times4,descending_step_size4,iteration_error4)
